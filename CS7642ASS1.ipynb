{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+C6dz0LDKJ8jrL3f/m5E6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castronyabola/test/blob/master/CS7642ASS1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. IT Expenditure Classification - Decision Tree Model"
      ],
      "metadata": {
        "id": "eM9rvZi7nF5O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1-LTmVwYz3C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, learning_curve, validation_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'IT_Expenditure_Data_Classification.csv'  # Replace with your dataset file path\n",
        "it_expenditure_df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data: One-hot encode categorical variables\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "X_categorical = one_hot_encoder.fit_transform(it_expenditure_df[['Company Size', 'Sector']])\n",
        "X_numerical = it_expenditure_df[['Total Revenue', 'IT Spending as % of Revenue']].values\n",
        "X = np.hstack((X_categorical.toarray(), X_numerical))\n",
        "y = it_expenditure_df['Rating']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Decision Tree model using Entropy\n",
        "decision_tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "print('Classification Report for Decision Trees (IT Expenditure Classification)')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Function to plot learning curves\n",
        "def plot_learning_curve(estimator, X, y, cv=5, n_jobs=4, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, return_times=True)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.title(\"Decision Trees Learning Curve (IT Expenditure Classification)\")\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plotting the learning curve\n",
        "plot_learning_curve(decision_tree, X, y)\n",
        "\n",
        "# Function to plot model complexity graph for 'max_depth'\n",
        "def plot_model_complexity_graph(estimator, X, y, cv=5, n_jobs=4, max_depth_range=np.arange(1, 15)):\n",
        "    train_scores, test_scores = validation_curve(\n",
        "        estimator, X, y, param_name=\"max_depth\", param_range=max_depth_range, cv=cv, scoring='accuracy', n_jobs=n_jobs)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.grid()\n",
        "    plt.fill_between(max_depth_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(max_depth_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(max_depth_range, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(max_depth_range, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.title(\"Decision Trees Model Complexity - Max Depth (IT Expenditure Classification)\")\n",
        "    plt.xlabel(\"Max Depth\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plotting model complexity graph for 'max_depth'\n",
        "plot_model_complexity_graph(decision_tree, X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It Expenditure Classification - Neural Networks"
      ],
      "metadata": {
        "id": "0PxC1MuOnV3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete code to preprocess the data, train an MLPClassifier, and plot learning and validation curves.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, learning_curve, validation_curve\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset with noise added previously\n",
        "file_path = 'IT_Expenditure_Data_Classification.csv'\n",
        "it_expenditure_noisy_df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data: One-hot encode categorical variables and scale numerical features\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# One-hot encoding for categorical features\n",
        "X_categorical_encoded = one_hot_encoder.fit_transform(it_expenditure_noisy_df[['Company Size', 'Sector']]).toarray()\n",
        "\n",
        "# Scaling numerical features\n",
        "X_numerical_scaled = scaler.fit_transform(it_expenditure_noisy_df.drop(columns=['Company Size', 'Sector', 'Rating']))\n",
        "\n",
        "# Combine categorical and numerical features\n",
        "X_combined = np.hstack((X_categorical_encoded, X_numerical_scaled))\n",
        "y = it_expenditure_noisy_df['Rating']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and train the MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print the classification report\n",
        "y_pred = mlp.predict(X_test)\n",
        "print('Classification Report for Neural Networks (IT Expenditure Classification)')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot learning curve\n",
        "train_sizes, train_scores, test_scores = learning_curve(mlp, X_train, y_train, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5))\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Neural Networks Learning Curve for MLPClassifier (IT Expenditure Classification)\")\n",
        "plt.xlabel(\"Training examples\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0.7, 1.01)\n",
        "plt.grid()\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "\n",
        "# Plot validation curve for 'max_iter' hyperparameter\n",
        "max_iter_range = np.linspace(100, 1000, 5).astype(int)\n",
        "train_scores, test_scores = validation_curve(mlp, X_train, y_train, param_name=\"max_iter\", param_range=max_iter_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Neural Networks Validation Curve with MLPClassifier - max_iter (IT Expenditure Classification)\")\n",
        "plt.xlabel(\"max_iter\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0.7, 1.01)\n",
        "plt.grid()\n",
        "plt.plot(max_iter_range, train_scores_mean,'o-', color=\"r\", label=\"Training score\")\n",
        "plt.fill_between(max_iter_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "plt.plot(max_iter_range, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(max_iter_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "egPg5EMbneYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Expenditure Classification - Boosted Decision trees\n"
      ],
      "metadata": {
        "id": "qrkPGLNTuW_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import validation_curve, learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'IT_Expenditure_Data_Classification.csv'\n",
        "it_expenditure_noisy_df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "scaler = StandardScaler()\n",
        "X_categorical_encoded = one_hot_encoder.fit_transform(it_expenditure_noisy_df[['Company Size', 'Sector']]).toarray()\n",
        "X_numerical_scaled = scaler.fit_transform(it_expenditure_noisy_df.drop(columns=['Company Size', 'Sector', 'Rating']))\n",
        "X_combined = np.hstack((X_categorical_encoded, X_numerical_scaled))\n",
        "y = it_expenditure_noisy_df['Rating']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize AdaBoost with Decision Trees as the base estimator\n",
        "ada_boost = AdaBoostClassifier(\n",
        "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the AdaBoost model\n",
        "ada_boost.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_ada = ada_boost.predict(X_test)\n",
        "print('Classification Report for Boosted Decision Trees (IT Expenditure Classification)')\n",
        "print(classification_report(y_test, y_pred_ada))\n",
        "\n",
        "# Corrected plot_learning_curve function\n",
        "def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_learning_curve(ada_boost, \"Learning Curve for AdaBoost (IT Expenditure Classification)\", X_train, y_train)\n",
        "\n",
        "# Function to plot model complexity curve\n",
        "def plot_model_complexity_curve(param_range, train_scores, test_scores, title):\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Number of Estimators\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.plot(param_range, train_scores_mean, 'o-',label=\"Training score\", color=\"r\")\n",
        "    plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.plot(param_range, test_scores_mean, 'o-',label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot the validation curve for AdaBoost 'n_estimators' parameter\n",
        "n_estimators_range = np.arange(10, 110, 10)\n",
        "train_scores, test_scores = validation_curve(\n",
        "    ada_boost, X_train, y_train, param_name=\"n_estimators\", param_range=n_estimators_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "plot_model_complexity_curve(n_estimators_range, train_scores, test_scores, \"AdaBoost Model Complexity - Number of Estimators (IT Expenditure Classification)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Vd27rBg8ue52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Expenditure Classification - Support Vector Machines"
      ],
      "metadata": {
        "id": "-5FYbx_eI7Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "file_path = 'IT_Expenditure_Data_Classification.csv'\n",
        "it_expenditure_noisy_df = pd.read_csv(file_path)\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "scaler = StandardScaler()\n",
        "X_categorical_encoded = one_hot_encoder.fit_transform(it_expenditure_noisy_df[['Company Size', 'Sector']]).toarray()\n",
        "X_numerical_scaled = scaler.fit_transform(it_expenditure_noisy_df.drop(columns=['Company Size', 'Sector', 'Rating']))\n",
        "X_combined = np.hstack((X_categorical_encoded, X_numerical_scaled))\n",
        "y = it_expenditure_noisy_df['Rating']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# SVM with RBF kernel\n",
        "svm_rbf = SVC(C=1.0, kernel='rbf', gamma='scale', random_state=42)\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = svm_rbf.predict(X_test)\n",
        "print(\"Classification Report for SVM with RBF Kernel (IT Expenditure Classification):\")\n",
        "print(classification_report(y_test, y_pred_rbf))\n",
        "\n",
        "# SVM with Linear kernel\n",
        "svm_linear = SVC(C=1.0, kernel='linear', random_state=42)\n",
        "svm_linear.fit(X_train, y_train)\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "print(\"\\nClassification Report for SVM with Linear Kernel (IT Expenditure Classification):\")\n",
        "print(classification_report(y_test, y_pred_linear))\n",
        "\n",
        "# Function to plot learning curve\n",
        "def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot learning curve for SVM with RBF Kernel\n",
        "plot_learning_curve(svm_rbf, \"Learning Curve for SVM with RBF Kernel (IT Expenditure Classification)\", X_train, y_train)\n",
        "\n",
        "# Plot learning curve for SVM with Linear Kernel\n",
        "plot_learning_curve(svm_linear, \"Learning Curve for SVM with Linear Kernel (IT Expenditure Classification)\", X_train, y_train)\n",
        "\n",
        "# Part 2B: Plotting Validation Curves for SVM Classifiers\n",
        "\n",
        "# Function to plot validation curve\n",
        "def plot_validation_curve(estimator, X, y, param_name, param_range, title, cv=5, n_jobs=None):\n",
        "    train_scores, test_scores = validation_curve(\n",
        "        estimator, X, y, param_name=param_name, param_range=param_range, cv=cv, scoring=\"accuracy\", n_jobs=n_jobs)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
        "    plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# C parameter range for validation curve\n",
        "C_range = np.logspace(-2, 2, 5)\n",
        "\n",
        "# Plotting Validation Curves for 'C' hyperparameter with RBF kernel\n",
        "plot_validation_curve(svm_rbf, X_train, y_train, \"C\", C_range, \"Validation Curve for SVM (RBF Kernel) - C parameter (IT Expenditure Classification)\")\n",
        "\n",
        "# Plotting Validation Curves for 'C' hyperparameter with Linear kernel\n",
        "plot_validation_curve(svm_linear, X_train, y_train, \"C\", C_range, \"Validation Curve for SVM (Linear Kernel) - C parameter (IT Expenditure Classification)\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U59RA9yIJE6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Expenditure Classification - k-Nearest Neighbours"
      ],
      "metadata": {
        "id": "pMYITetQKX9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import validation_curve, learning_curve, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'IT_Expenditure_Data_Classification.csv'\n",
        "it_expenditure_noisy_df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data: One-hot encode categorical variables and scale numerical features\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "scaler = StandardScaler()\n",
        "X_categorical_encoded = one_hot_encoder.fit_transform(it_expenditure_noisy_df[['Company Size', 'Sector']]).toarray()\n",
        "X_numerical_scaled = scaler.fit_transform(it_expenditure_noisy_df.drop(columns=['Company Size', 'Sector', 'Rating']))\n",
        "X_combined = np.hstack((X_categorical_encoded, X_numerical_scaled))\n",
        "y = it_expenditure_noisy_df['Rating']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a range for 'k' (number of neighbors)\n",
        "k_range = np.arange(1, 31)\n",
        "\n",
        "# Train k-NN Classifier and evaluate for different values of 'k'\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "    print(f\"\\nClassification Report for k-NN with k={k} (IT Expenditure Classification):\")\n",
        "    print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Function to plot learning curve\n",
        "def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot learning curve for k-NN with 5 neighbors as an example\n",
        "plot_learning_curve(KNeighborsClassifier(n_neighbors=5), \"Learning Curve for k-NN (IT Expenditure Classification)\", X_train, y_train)\n",
        "\n",
        "# Function to plot validation curve\n",
        "def plot_knn_validation_curve(X, y, k_range, title, cv=5):\n",
        "    train_scores, test_scores = validation_curve(\n",
        "        KNeighborsClassifier(), X, y, param_name=\"n_neighbors\", param_range=k_range, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Number of Neighbors\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.plot(k_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
        "    plt.fill_between(k_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.plot(k_range, test_scores_mean, label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(k_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot validation curve for k-NN\n",
        "plot_knn_validation_curve(X_train, y_train, k_range, \"Validation Curve for k-NN (IT Expenditure Classification)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_SqEIkfnOI-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Infrastructure Classification - Decision Trees"
      ],
      "metadata": {
        "id": "XK4aWn04Zgpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's adapt the code to work with the IT Infrastructure dataset.\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, learning_curve, validation_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'IT_Infrastructure_Data_Modified.csv'  # Replace with your dataset file path\n",
        "it_infrastructure_df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data: One-hot encode categorical variables\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "X = one_hot_encoder.fit_transform(it_infrastructure_df.drop('Rating', axis=1))\n",
        "y = it_infrastructure_df['Rating']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Decision Tree model using Entropy\n",
        "decision_tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "print('Classification Report for Decision Trees (IT Infrastructure Classification)')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Function to plot learning curves\n",
        "def plot_learning_curve(estimator, X, y, cv=5, n_jobs=4, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, return_times=True)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.title(\"Decision Trees Learning Curve (IT Infrastructure Classification)\")\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plotting the learning curve\n",
        "plot_learning_curve(decision_tree, X, y)\n",
        "\n",
        "# Function to plot model complexity graph for 'max_depth'\n",
        "def plot_model_complexity_graph(estimator, X, y, cv=5, n_jobs=4, max_depth_range=np.arange(1, 15)):\n",
        "    train_scores, test_scores = validation_curve(\n",
        "        estimator, X, y, param_name=\"max_depth\", param_range=max_depth_range, cv=cv, scoring='accuracy', n_jobs=n_jobs)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.grid()\n",
        "    plt.fill_between(max_depth_range, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(max_depth_range, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(max_depth_range, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(max_depth_range, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.title(\"Decision Trees Model Complexity - Max Depth (IT Infrastructure Classification)\")\n",
        "    plt.xlabel(\"Max Depth\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plotting model complexity graph for 'max_depth'\n",
        "plot_model_complexity_graph(decision_tree, X, y)\n",
        "\n"
      ],
      "metadata": {
        "id": "lkkbJav4Zlan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Infrastructure Dataset - Neural Networks"
      ],
      "metadata": {
        "id": "pvhV3et6yfvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's adapt the code to work with the IT Infrastructure dataset using an MLPClassifier.\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, learning_curve, validation_curve\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'IT_Infrastructure_Data_Modified.csv'\n",
        "df_infrastructure = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data: One-hot encode categorical variables\n",
        "encoder = OneHotEncoder()\n",
        "X = encoder.fit_transform(df_infrastructure.drop('Rating', axis=1))\n",
        "y = df_infrastructure['Rating']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and train the MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print the classification report\n",
        "y_pred = mlp.predict(X_test)\n",
        "print('Classification Report for Neural Networks (IT Infrastructure Classification)')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Plot learning curve\n",
        "train_sizes, train_scores, test_scores = learning_curve(mlp, X_train, y_train, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5))\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Neural Networks Learning Curve for MLPClassifier (IT Infrastructure Classification)\")\n",
        "plt.xlabel(\"Training examples\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0.7, 1.01)\n",
        "plt.grid()\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "\n",
        "# Plot validation curve for 'max_iter' hyperparameter\n",
        "max_iter_range = np.linspace(100, 1000, 5).astype(int)\n",
        "train_scores, test_scores = validation_curve(mlp, X_train, y_train, param_name=\"max_iter\", param_range=max_iter_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Neural Networks Validation Curve with MLPClassifier (max_iter) (IT Infrastructure Classification)\")\n",
        "plt.xlabel(\"max_iter\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0.7, 1.01)\n",
        "plt.grid()\n",
        "plt.plot(max_iter_range, train_scores_mean,'o-', color=\"r\", label=\"Training score\")\n",
        "plt.fill_between(max_iter_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "plt.plot(max_iter_range, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(max_iter_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "9R5XXhC7yk7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Infrastructure Classification - Boosted Decision Trees"
      ],
      "metadata": {
        "id": "_-O70mmu0Py0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's modify the provided code to work with the IT Infrastructure dataset using AdaBoostClassifier.\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import validation_curve, learning_curve, train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'IT_Infrastructure_Data_Modified.csv'  # Adjust path as needed\n",
        "it_infrastructure_df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data: One-hot encode categorical variables\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "X = one_hot_encoder.fit_transform(it_infrastructure_df.drop('Rating', axis=1))\n",
        "y = it_infrastructure_df['Rating']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize AdaBoost with Decision Trees as the base estimator\n",
        "ada_boost = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=3),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the AdaBoost model\n",
        "ada_boost.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_ada = ada_boost.predict(X_test)\n",
        "print('Classification Report for Boosted Decision Trees (IT Infrastructure Classification)')\n",
        "print(classification_report(y_test, y_pred_ada))\n",
        "\n",
        "# Corrected plot_learning_curve function\n",
        "def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_learning_curve(ada_boost, \"Boosted Decision Trees Learning Curve for AdaBoost (IT Infrastructure Classification)\", X_train, y_train)\n",
        "\n",
        "# Function to plot model complexity curve\n",
        "def plot_model_complexity_curve(estimator, X, y, title, param_name, param_range):\n",
        "    train_scores, test_scores = validation_curve(\n",
        "        estimator, X, y, param_name=param_name, param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.plot(param_range, train_scores_mean, 'o-',label=\"Training score\", color=\"r\")\n",
        "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.plot(param_range, test_scores_mean, 'o-',label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot the validation curve for AdaBoost 'n_estimators' parameter\n",
        "n_estimators_range = np.arange(10, 110, 10)\n",
        "plot_model_complexity_curve(ada_boost, X_train, y_train, \"Boosted Decision Trees AdaBoost Model Complexity - Number of Estimators (IT Infrastructure Classification)\", \"n_estimators\", n_estimators_range)\n",
        "\n"
      ],
      "metadata": {
        "id": "RYA-M8ZR0QtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Infrastructure Classification - Support Vector Machines"
      ],
      "metadata": {
        "id": "XNv2TKNc32Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapting the code to work with the IT Infrastructure dataset using SVM classifiers.\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, learning_curve, validation_curve\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'IT_Infrastructure_Data_Modified.csv'  # Adjust path as needed\n",
        "df_infrastructure = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data: One-hot encode categorical variables\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "X = one_hot_encoder.fit_transform(df_infrastructure.drop('Rating', axis=1))\n",
        "y = df_infrastructure['Rating']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# SVM with RBF kernel\n",
        "svm_rbf = SVC(C=1.0, kernel='rbf', gamma='scale', random_state=42)\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = svm_rbf.predict(X_test)\n",
        "print(\"Classification Report for SVM with RBF Kernel (IT Infrastructure Classification):\")\n",
        "print(classification_report(y_test, y_pred_rbf))\n",
        "\n",
        "# SVM with Linear kernel\n",
        "svm_linear = SVC(C=1.0, kernel='linear', random_state=42)\n",
        "svm_linear.fit(X_train, y_train)\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "print(\"\\nClassification Report for SVM with Linear Kernel (IT Infrastructure Classification):\")\n",
        "print(classification_report(y_test, y_pred_linear))\n",
        "\n",
        "# Plot learning curve function\n",
        "def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot learning curves for SVM classifiers\n",
        "plot_learning_curve(svm_rbf, \"Learning Curve for SVM with RBF Kernel (IT Infrastructure Classification)\", X_train, y_train)\n",
        "plot_learning_curve(svm_linear, \"Learning Curve for SVM with Linear Kernel (IT Infrastructure Classification)\", X_train, y_train)\n",
        "\n",
        "# Plot validation curve function\n",
        "def plot_validation_curve(estimator, X, y, param_name, param_range, title, cv=5, n_jobs=None):\n",
        "    train_scores, test_scores = validation_curve(\n",
        "        estimator, X, y, param_name=param_name, param_range=param_range, cv=cv, scoring=\"accuracy\", n_jobs=n_jobs)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.plot(param_range, train_scores_mean, 'o-',label=\"Training score\", color=\"r\")\n",
        "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.plot(param_range, test_scores_mean,'o-', label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# C parameter range for validation curves\n",
        "C_range = np.logspace(-2, 2, 5)\n",
        "\n",
        "# Plotting Validation Curves for 'C' hyperparameter with RBF kernel\n",
        "plot_validation_curve(svm_rbf, X_train, y_train, \"C\", C_range, \"Validation Curve for SVM (RBF Kernel) - C parameter (IT Infrastructure Classification)\")\n",
        "\n",
        "# Plotting Validation Curves for 'C' hyperparameter with Linear kernel\n",
        "plot_validation_curve(svm_linear, X_train, y_train, \"C\", C_range, \"Validation Curve for SVM (Linear Kernel) - C parameter (IT Infrastructure Classification)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AKo2sZpc3_v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Infrastructure Classification - k-Nearest Neighbours"
      ],
      "metadata": {
        "id": "qHiYA-l45w2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapting the code to work with the IT Infrastructure dataset using KNeighborsClassifier.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import validation_curve, learning_curve, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'IT_Infrastructure_Data_Modified.csv'  # Adjust path as needed\n",
        "it_infrastructure_df = pd.read_csv(file_path)\n",
        "\n",
        "# Preprocess the data: One-hot encode categorical variables\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "X = one_hot_encoder.fit_transform(it_infrastructure_df.drop('Rating', axis=1))\n",
        "y = it_infrastructure_df['Rating']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a range for 'k' (number of neighbors)\n",
        "k_range = np.arange(1, 31)\n",
        "\n",
        "# Train k-NN Classifier and evaluate for different values of 'k'\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "    print(f\"\\nClassification Report for k-NN with k={k} (IT Infrastructure Classification):\")\n",
        "    print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Function to plot learning curve\n",
        "def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot learning curve for k-NN with 5 neighbors as an example\n",
        "plot_learning_curve(KNeighborsClassifier(n_neighbors=5), \"Learning Curve for k-NN (IT Infrastructure Classification)\", X_train, y_train)\n",
        "\n",
        "# Function to plot validation curve\n",
        "def plot_knn_validation_curve(X, y, k_range, title, cv=5):\n",
        "    train_scores, test_scores = validation_curve(\n",
        "        KNeighborsClassifier(), X, y, param_name=\"n_neighbors\", param_range=k_range, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Number of Neighbors\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.7, 1.01)\n",
        "    plt.grid()\n",
        "    plt.plot(k_range, train_scores_mean, 'o-',label=\"Training score\", color=\"r\")\n",
        "    plt.fill_between(k_range, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.plot(k_range, test_scores_mean, 'o-',label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(k_range, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot validation curve for k-NN\n",
        "plot_knn_validation_curve(X_train, y_train, k_range, \"Validation Curve for k-NN (IT Infrastructure Classification)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RgmWQjZn5ztu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}